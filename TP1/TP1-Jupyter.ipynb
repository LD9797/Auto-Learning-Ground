{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MC8843 - Aprendizaje Automático**\n",
    "# **Trabajo práctico 1: Árboles de decisión**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-requisitos para el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:35.656962200Z",
     "start_time": "2024-04-08T04:25:32.916646400Z"
    },
    "id": "aI7oDlIsH7yw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas\n",
    "import numpy as np\n",
    "import optuna\n",
    "import plotly\n",
    "import pytest\n",
    "from xmldiff import main  # pip install xmldiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dHTWUKUH7yt"
   },
   "source": [
    "## **1. Implementación de la clasificación multi-clase con árboles de decisión (60 puntos)**\n",
    "\n",
    "A continuación, implemente el algoritmo de maximización de la esperanza (descrito en el material del curso), usando la definición y descripción de las siguientes funciones como base:\n",
    "\n",
    "1. El conjunto de datos disponible en https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms corresponde a lecturas de 7 fuentes de señal Wi-Fi, los cuales pretender ser utilizados para determinar si el receptor de las lecturas se encuentra en la habitación 1, 2, 3 o 4. La Figura 1 muestra una muestra del conjunto de datos, donde se observa que usualmente las lecturas de la señal Wi-Fi son valores negativos.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <figure>\n",
    "    <img src=\"images/sample.png\" alt=\"sample\">\n",
    "    <figcaption>Figura 1: Muestra del conjunto de datos a utilizar.</figcaption>\n",
    "  </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:37.869770200Z",
     "start_time": "2024-04-08T04:25:37.839704300Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_dataset(csv_name='wifi_localization.txt'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param csv_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_frame = pandas.read_table(csv_name, sep=r'\\s+', names=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'ROOM'),\n",
    "                                   dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,\n",
    "                                          'E': np.float64, 'F': np.float64, 'G': np.float64, 'ROOM': np.float64})\n",
    "    # targets_torch = torch.tensor(data_frame['ROOM'].values)\n",
    "    dataset_torch = torch.tensor(data_frame.values)\n",
    "    return dataset_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:38.662139700Z",
     "start_time": "2024-04-08T04:25:38.611231800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-64., -56., -61.,  ..., -82., -81.,   1.],\n",
      "        [-68., -57., -61.,  ..., -85., -85.,   1.],\n",
      "        [-63., -60., -60.,  ..., -85., -84.,   1.],\n",
      "        ...,\n",
      "        [-62., -59., -46.,  ..., -87., -88.,   4.],\n",
      "        [-62., -58., -52.,  ..., -90., -85.,   4.],\n",
      "        [-59., -50., -45.,  ..., -88., -87.,   4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dataset_torch = read_dataset()\n",
    "\n",
    "print(dataset_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Para resolver el problema de discriminar en cual habitación se encuentra el receptor de la señal Wi-Fi, su equipo decidió construir un arbol de decisión (CART por sus siglas en inglés). Para ello utilizará el código provisto en el \"notebook\" de \"Jupyter\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) El código provisto define las clases \"CART\" y \"Node_CART\", las cuales permiten construir un CART binario. Cada nodo del árbol tiene atributos como el \"feature\", el umbral, y el coeficiente de \"gini\" (o la entropía) de la partición definida en tal nodo. Además define el atributo \"dominant_class\" para el nodo, el cual es el resultado de calcular la clase con mayor cantidad de apariciones en la partición que define al nodo. Finalmente el código incluye la funcionalidad para generar un archivo \"xml\" (el cual se puede abrir en cualquier navegador web), para representar fácilmente el árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) (10 puntos)** Implemente el método \"calculate_gini(data_partition_torch, num_classes = 4)\", el cual calcule el coeficiente de gini para el conjunto de datos recibido en un tensor de \"pytorch\". Para ello utilice la definición indicada en el material del curso. Realice una implementación matricial (prescindiendo de estructuras de repetición al máximo). Comente la implementación, detallando cada función utilizada en la documentación externa.\n",
    "\n",
    "$E_{\\textrm{gini},\\rho}\\left(\\tau_{d}\\right)=1-\\sum_{k=1}^{K}a_{k}^{2}$\n",
    "\n",
    "1) Diseñe e implemente al menos 2 pruebas unitarias para esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:41.721462900Z",
     "start_time": "2024-04-08T04:25:41.678958700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unitary tests for Gini, the functions here are the exact same as the ones used in the CART classes.\n",
    "These tests reach 100% code coverage.\n",
    "\"\"\"\n",
    "def calculate_gini(data_partition_torch):\n",
    "    def calculate_gini_impurity(partition):\n",
    "        size = partition.shape[0]\n",
    "        if size == 0:  # To handle the division by zero\n",
    "            return torch.tensor(0)\n",
    "        length = partition.shape[1] - 1\n",
    "        _, counts = partition[:, length].unique(return_counts=True)\n",
    "        gini = 1 - torch.sum((counts/size) ** 2)\n",
    "        return gini\n",
    "    return calculate_gini_impurity(data_partition_torch)\n",
    "\n",
    "\n",
    "data = [\n",
    "        [-64, -56, -61, -66, -71, -82, -81, 1],\n",
    "        [-68, -57, -61, -65, -71, -85, -85, 1],\n",
    "        [-42, -53, -62, -38, -66, -65, -69, 2],\n",
    "        [-44, -55, -61, -41, -66, -72, -68, 2]\n",
    "    ]\n",
    "\n",
    "data_left = [\n",
    "    [-64, -56, -61, -66, -71, -82, -81, 1],\n",
    "    [-68, -57, -61, -65, -71, -85, -85, 2]\n",
    "]\n",
    "\n",
    "data_right = [\n",
    "    [-42, -53, -62, -38, -66, -65, -69, 1],\n",
    "    [-44, -55, -61, -41, -66, -72, -68, 1]\n",
    "]\n",
    "\n",
    "\n",
    "def test_calculate_gini():\n",
    "    \"\"\"\n",
    "    Unit test for calculate_gini. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    partition = torch.tensor(data)\n",
    "    gini = calculate_gini(partition)\n",
    "    assert gini.item() == 0.5\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_calculate_empty_gini():\n",
    "    \"\"\"\n",
    "    Unit test for calculate_gini. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    partition = torch.tensor([])\n",
    "    gini = calculate_gini(partition)\n",
    "    assert gini.item() == 0\n",
    "    print(\"PASSED\")\n",
    "\n",
    "test_calculate_gini()\n",
    "test_calculate_empty_gini()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) (10 puntos)** Implemente el método calculate_entropy(data_partition_torch, num_classes = 4), }el cual calcule la entropía de las etiquetas, representadas en un tensor de pytorch. Para ello utilice la definición indicada en el material del curso. Realice una implementación matricial (prescindiendo de estructuras de repetición al máximo). $p\\left[k\\right]$ es la función de densidad de las etiquetas en la partición de datos recibida por parámetro.\n",
    "\n",
    "$E_{\\textrm{entropy},\\rho}\\left(\\tau_{d}\\right)=-\\sum_{k=1}^{K}p\\left[k\\right]\\log\\left(p\\left[k\\right]\\right)$\n",
    "\n",
    "1) Diseñe e implemente al menos 2 pruebas unitarias para esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:43.678668700Z",
     "start_time": "2024-04-08T04:25:43.650149400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unitary tests for Entropy, the functions here are the exact same as the ones used in the classes.\n",
    "These tests reach 100% code coverage.\n",
    "\"\"\"\n",
    "def calculate_entropy(data_partition_torch):\n",
    "    def calculate_entropy_disorder(partition):\n",
    "        size = partition.shape[0]\n",
    "        if size == 0:  # To handle the division by zero\n",
    "            return torch.tensor(0)\n",
    "        length = partition.shape[1] - 1\n",
    "        epsilon = torch.tensor(0.0001)  # Small epsilon to prevent probabilities equal to 0\n",
    "        _, counts = partition[:, length].unique(return_counts=True)\n",
    "        probabilities = (counts / size) + epsilon\n",
    "        entropy = - torch.sum(probabilities * torch.log(probabilities))\n",
    "        return entropy\n",
    "    return calculate_entropy_disorder(data_partition_torch)\n",
    "\n",
    "data = [\n",
    "        [-64, -56, -61, -66, -71, -82, -81, 1],\n",
    "        [-68, -57, -61, -65, -71, -85, -85, 1],\n",
    "        [-42, -53, -62, -38, -66, -65, -69, 2],\n",
    "        [-44, -55, -61, -41, -66, -72, -68, 2]\n",
    "    ]\n",
    "\n",
    "data_left = [\n",
    "    [-64, -56, -61, -66, -71, -82, -81, 1],\n",
    "    [-68, -57, -61, -65, -71, -85, -85, 2]\n",
    "]\n",
    "\n",
    "data_right = [\n",
    "    [-42, -53, -62, -38, -66, -65, -69, 1],\n",
    "    [-44, -55, -61, -41, -66, -72, -68, 1]\n",
    "]\n",
    "\n",
    "\n",
    "def test_calculate_entropy():\n",
    "    \"\"\"\n",
    "    Unit test for calculate_entropy. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    partition = torch.tensor(data)\n",
    "    entropy = calculate_entropy(partition)\n",
    "    assert round(entropy.item(), 3) == 0.693\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_calculate_empty_entropy():\n",
    "    \"\"\"\n",
    "    Unit test for calculate_entropy. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    partition = torch.tensor([])\n",
    "    entropy = calculate_entropy(partition)\n",
    "    assert entropy.item() == 0\n",
    "    print(\"PASSED\")\n",
    "\n",
    "test_calculate_entropy()\n",
    "test_calculate_empty_entropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) (30 puntos)** Implemente los métodos \"select_best_feature_and_thresh(data_torch, num_classes = 4)\" y \"create_with_children\", de la clase \"Node_CART\". Este método recibe como parámetros el conjunto de datos en un tensor tipo torch a analizar. El método debe probar de forma extensiva todos los posibles features y sus correspondientes umbrales en los datos recibidos, hasta dar con el menor coeficiente ponderado de gini (o la mínima entropía, dependiendo de la función de error a utilizar). **Utilice indexación lógica para evitar al máximo el uso de estructuras de repetición tipo** \"for\". Solamente puede usar estructuras de repetición para iterar por los \"features\" y posibles umbrales dentro del conjunto de datos. Recuerde que para evaluar una posible partición, es necesario calcular el coeficiente de gini ponderado sugerido para decidir el feature y umbral óptimos es:\n",
    "\n",
    "$\\overline{E}_{\\textrm{gini}}\\left(\\tau_{d},d\\right)=\\frac{n_{i}}{n}E_{\\textrm{gini}}\\left(D_{i}\\right)+\\frac{n_{d}}{n}E_{\\textrm{gini}}\\left(D_{d}\\right).$\n",
    "\n",
    "Con un ponderado similar para la entropía. Comente la implementación, detallando cada función utilizada en la documentación externa.\n",
    "\n",
    "1) Diseñe e implemente al menos 2 pruebas unitarias para esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:45.944460400Z",
     "start_time": "2024-04-08T04:25:45.924226200Z"
    }
   },
   "outputs": [],
   "source": [
    "class NodeCart:\n",
    "\n",
    "    def __init__(self,\n",
    "                 gini_entropy_function=\"GINI\",\n",
    "                 num_classes=4, num_features=7, ref_cart=None, current_depth=0):\n",
    "        \"\"\"\n",
    "\n",
    "        :param num_classes:\n",
    "        :param ref_cart:\n",
    "        :param current_depth:\n",
    "        \"\"\"\n",
    "        self.ref_CART = ref_cart\n",
    "        self.threshold_value = 0  # Umbral\n",
    "        self.feature_num = 0\n",
    "        self.node_right = None\n",
    "        self.node_left = None\n",
    "        self.data_torch_partition = None  # Referencia a la partición del dato\n",
    "        self.gini = 0  # O Entropia. Funcion numerica a utilizar cuando se construya el arbol.\n",
    "        self.dominant_class = None  # Clase con mayor cantidad de observaciones en esa particion.\n",
    "        self.accuracy_dominant_class = None  # Tasa de aciertos de esa clase dominante\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        self.current_depth = current_depth  # Profundidad\n",
    "        self.leaf = False\n",
    "        self.gini_function = gini_entropy_function\n",
    "        self.hits = 0\n",
    "        self.fails = 0\n",
    "\n",
    "    def to_xml(self, current_str=\"\"):\n",
    "        \"\"\"\n",
    "        Recursive function to write the node content to an xml formatted string\n",
    "        param current_str : the xml content so far in the whole tree\n",
    "        return the string with the node content\n",
    "        \"\"\"\n",
    "        str_node = (f\"<node>\"\n",
    "                    f\"<thresh>{self.threshold_value}</thresh>\"\n",
    "                    f\"<feature>{self.feature_num}</feature>\"\n",
    "                    f\"<depth>{self.current_depth}</depth>\"\n",
    "                    f\"<gini>{self.gini}</gini>\")\n",
    "        if self.node_left:\n",
    "            str_left = self.node_left.to_xml(current_str)\n",
    "            str_node += str_left\n",
    "        if self.node_right:\n",
    "            str_right = self.node_right.to_xml(current_str)\n",
    "            str_node += str_right\n",
    "        if self.is_leaf():\n",
    "            str_node += (f\"<dominant_class>{self.dominant_class}</dominant_class>\"\n",
    "                         f\"<acc_dominant_class>{self.accuracy_dominant_class}</acc_dominant_class>\")\n",
    "        str_node += \"</node>\"\n",
    "        return str_node\n",
    "\n",
    "    def is_leaf(self):\n",
    "        \"\"\"\n",
    "        Checks whether the node is a leaf\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.leaf\n",
    "\n",
    "    def create_with_children(self, current_depth=0, list_selected_features=None, min_gini=0.000001, max_cart_depth=3,\n",
    "                             min_observations=2, glob_list_selected_features=None):\n",
    "        \"\"\"\n",
    "        Creates a node by selecting the best feature and threshold, and if needed, creating its children\n",
    "        param data_torch: dataset with the current partition to deal with in the node\n",
    "        param current_depth: depth counter for the node\n",
    "        param list_selected_features: list of selected features so far for the CART building process\n",
    "        param min_gini: hyperparameter selected by the user defining the minimum tolerated Gini coefficient for a node\n",
    "        return the list of selected features so far\n",
    "        \"\"\"\n",
    "\n",
    "        if list_selected_features is None:\n",
    "            list_selected_features = []\n",
    "\n",
    "        if glob_list_selected_features is None:\n",
    "            glob_list_selected_features = []\n",
    "\n",
    "        min_thresh, min_feature, min_gini_thresh = (\n",
    "            self.select_best_feature_and_thresh(data_torch=self.data_torch_partition,\n",
    "                                                list_features_selected=list_selected_features))\n",
    "\n",
    "        self.feature_num = min_feature\n",
    "        self.threshold_value = min_thresh\n",
    "        self.gini = min_gini_thresh\n",
    "        self.current_depth = current_depth\n",
    "        list_selected_features.append(self.feature_num)\n",
    "\n",
    "        if (min_gini_thresh <= min_gini or len(list_selected_features) == self.num_features or\n",
    "                current_depth == max_cart_depth or self.data_torch_partition.shape[0] <= min_observations):\n",
    "            # This is a leaf\n",
    "            self.leaf = True\n",
    "            length = self.data_torch_partition.shape[1] - 1\n",
    "            tag_values = self.data_torch_partition[:, length:length + 1].squeeze()\n",
    "            tags, counts = tag_values.unique(return_counts=True)\n",
    "            most_common_value = tags[counts.argmax()].item()\n",
    "            self.dominant_class = most_common_value\n",
    "            return list_selected_features\n",
    "\n",
    "        left_idx = self.data_torch_partition[:, self.feature_num] < self.threshold_value\n",
    "        right_idx = self.data_torch_partition[:, self.feature_num] >= self.threshold_value\n",
    "\n",
    "        dataset_partition_left = self.data_torch_partition[left_idx]\n",
    "        dataset_partition_right = self.data_torch_partition[right_idx]\n",
    "\n",
    "        left_child = NodeCart(current_depth=current_depth, gini_entropy_function=self.gini_function)\n",
    "        left_child.data_torch_partition = dataset_partition_left\n",
    "        left_child.ref_CART = self\n",
    "\n",
    "        right_child = NodeCart(current_depth=current_depth, gini_entropy_function=self.gini_function)\n",
    "        right_child.data_torch_partition = dataset_partition_right\n",
    "        right_child.gini_function = self.gini_function\n",
    "        right_child.ref_CART = self\n",
    "\n",
    "        current_depth += 1\n",
    "\n",
    "        self.node_left = left_child\n",
    "        self.node_right = right_child\n",
    "\n",
    "        unique_features_left = list_selected_features.copy()\n",
    "        unique_features_right = list_selected_features.copy()\n",
    "\n",
    "        left_selected = self.node_left.create_with_children(current_depth, unique_features_left,\n",
    "                                                            max_cart_depth=max_cart_depth,\n",
    "                                                            min_gini=min_gini,\n",
    "                                                            min_observations=min_observations)\n",
    "        right_selected = self.node_right.create_with_children(current_depth, unique_features_right,\n",
    "                                                              min_gini=min_gini,\n",
    "                                                              max_cart_depth=max_cart_depth,\n",
    "                                                              min_observations=min_observations)\n",
    "\n",
    "        glob_list_selected_features.extend(left_selected)\n",
    "        glob_list_selected_features.extend(right_selected)\n",
    "\n",
    "        # TODO eliminar duplicados\n",
    "\n",
    "        return glob_list_selected_features\n",
    "\n",
    "    def select_best_feature_and_thresh(self, data_torch, list_features_selected=None, num_classes=4):\n",
    "        \"\"\"\n",
    "        Selects the best feature and threshold that minimizes the Gini coefficient\n",
    "        param data_torch: dataset partition to analyze\n",
    "        param list_features_selected list of features selected so far, thus must be ignored\n",
    "        param num_classes: number of K classes to discriminate from\n",
    "        return min_thresh, min_feature, min_gini found for the dataset partition when\n",
    "        selecting the found feature and threshold\n",
    "        \"\"\"\n",
    "        def evaluate_feature(data, feature_num, gini_entropy_total_function):\n",
    "            root_node = NodeCart()\n",
    "            root_node.data_torch_partition = data\n",
    "            root_node.feature_num = feature_num\n",
    "            threshold_values = torch.unique(data[:, feature_num:feature_num + 1].squeeze())\n",
    "            value_gini = {}\n",
    "            for value in threshold_values:\n",
    "                root_node.threshold_value = value\n",
    "                left_idx = data[:, root_node.feature_num] < root_node.threshold_value\n",
    "                right_idx = data[:, root_node.feature_num] >= root_node.threshold_value\n",
    "                dataset_partition_left = data[left_idx]\n",
    "                dataset_partition_right = data[right_idx]\n",
    "                left_child = NodeCart()\n",
    "                left_child.data_torch_partition = dataset_partition_left\n",
    "                right_child = NodeCart()\n",
    "                right_child.data_torch_partition = dataset_partition_right\n",
    "                gini = gini_entropy_total_function(left_child, right_child)\n",
    "                value_gini[value] = gini\n",
    "            minimum_gini = min(value_gini, key=value_gini.get)\n",
    "            return {minimum_gini.item(): value_gini[minimum_gini].item()}\n",
    "\n",
    "        if list_features_selected is None:\n",
    "            list_features_selected = []\n",
    "        num_features = data_torch.shape[1] - 1\n",
    "        if len(list_features_selected) == num_features:\n",
    "            raise ValueError(\"All features have been selected\")\n",
    "        features_gini = {}\n",
    "        for feature in range(num_features):\n",
    "            if feature not in list_features_selected:\n",
    "                features_gini[feature] = evaluate_feature(data_torch, feature, self.calculate_total_gini_entropy)\n",
    "        min_key, min_inner_dict = min(features_gini.items(), key=lambda item: next(iter(item[1].values())))\n",
    "        result = features_gini[min_key]\n",
    "        min_feature = min_key\n",
    "        min_thresh = list(result.keys())[0]\n",
    "        min_gini = result[min_thresh]\n",
    "        return min_thresh, min_feature, min_gini\n",
    "\n",
    "    def calculate_gini(self, data_partition_torch, num_classes=4):\n",
    "        \"\"\"\n",
    "        Calculates the Gini coefficient for a given partition with the given number of classes\n",
    "        param data_partition_torch: current dataset partition as a tensor\n",
    "        param num_classes: K number of classes to discriminate from\n",
    "        returns the calculated Gini coefficient\n",
    "        \"\"\"\n",
    "        def calculate_gini_impurity(partition):\n",
    "            size = partition.shape[0]\n",
    "            if size == 0:  # To handle the division by zero\n",
    "                return torch.tensor(0)\n",
    "            length = partition.shape[1] - 1\n",
    "            _, counts = partition[:, length].unique(return_counts=True)\n",
    "            gini = 1 - torch.sum((counts / size) ** 2)\n",
    "            return gini\n",
    "        return calculate_gini_impurity(data_partition_torch)\n",
    "\n",
    "    def calculate_entropy(self, data_partition_torch, num_classes=4):\n",
    "        \"\"\"\n",
    "        Calculates the Gini coefficient for a given partition with the given number of classes\n",
    "        param data_partition_torch: current dataset partition as a tensor\n",
    "        param num_classes: K number of classes to discriminate from\n",
    "        returns the calculated Gini coefficient\n",
    "        \"\"\"\n",
    "        def calculate_entropy_disorder(partition):\n",
    "            size = partition.shape[0]\n",
    "            if size == 0:  # To handle the division by zero\n",
    "                return torch.tensor(0)\n",
    "            length = partition.shape[1] - 1\n",
    "            epsilon = torch.tensor(0.0001)  # Small epsilon to prevent probabilities equal to 0\n",
    "            _, counts = partition[:, length].unique(return_counts=True)\n",
    "            probabilities = (counts / size) + epsilon\n",
    "            entropy = - torch.sum(probabilities * torch.log(probabilities))\n",
    "            return entropy\n",
    "        return calculate_entropy_disorder(data_partition_torch)\n",
    "\n",
    "    def calculate_total_gini_entropy(self, node_left, node_right):\n",
    "        selected_function = self.calculate_gini if self.gini_function == \"GINI\" else self.calculate_entropy\n",
    "        size_left = node_left.data_torch_partition.shape[0]\n",
    "        size_right = node_right.data_torch_partition.shape[0]\n",
    "        size_total = size_left + size_right\n",
    "        gini_entropy_left = selected_function(node_left.data_torch_partition)\n",
    "        gini_entropy_right = selected_function(node_right.data_torch_partition)\n",
    "        gini_entropy_total = (size_left / size_total) * gini_entropy_left + (size_right / size_total) * gini_entropy_right\n",
    "        return gini_entropy_total\n",
    "\n",
    "    def evaluate_node(self, input_torch):\n",
    "        \"\"\"\n",
    "        Evaluates an input observation within the node.\n",
    "        If is not a leaf node, send it to the corresponding node\n",
    "        return predicted label\n",
    "        \"\"\"\n",
    "        feature_val_input = input_torch[self.feature_num]\n",
    "        if self.is_leaf():\n",
    "            return self.dominant_class, self\n",
    "        elif feature_val_input < self.threshold_value:\n",
    "            return self.node_left.evaluate_node(input_torch)\n",
    "        else:\n",
    "            return self.node_right.evaluate_node(input_torch)\n",
    "\n",
    "    def update_accuracy(self):\n",
    "        self.accuracy_dominant_class = (self.hits / (self.hits + self.fails)) * 100\n",
    "        self.accuracy_dominant_class = round(self.accuracy_dominant_class, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:46.999440800Z",
     "start_time": "2024-04-08T04:25:46.986506500Z"
    }
   },
   "outputs": [],
   "source": [
    "class CART: \n",
    "    # Do not change default values or unit tests will be affected !!\n",
    "    def __init__(self, dataset_torch, max_cart_depth=3, min_observations=2, gini_entropy_function=\"GINI\", num_classes=4):\n",
    "        \"\"\"\n",
    "        CART has only one root node\n",
    "        \"\"\"\n",
    "        # min observations per node\n",
    "        self.min_observations = min_observations\n",
    "        self.root = NodeCart(num_classes=num_classes, ref_cart=self, gini_entropy_function=gini_entropy_function)\n",
    "        self.root.data_torch_partition = dataset_torch\n",
    "        self.max_CART_depth = max_cart_depth\n",
    "        self.list_selected_features = []\n",
    "        self.confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "    def get_root(self):\n",
    "        \"\"\"\n",
    "        Gets tree root\n",
    "        \"\"\"\n",
    "        return self.root\n",
    "\n",
    "    def get_min_observations(self):\n",
    "        \"\"\"\n",
    "        return min observations per node\n",
    "        \"\"\"\n",
    "        return self.min_observations\n",
    "\n",
    "    def get_max_depth(self):\n",
    "        \"\"\"\n",
    "        Gets the selected max depth of the tree\n",
    "        \"\"\"\n",
    "        return self.max_CART_depth\n",
    "\n",
    "    def build_cart(self):\n",
    "        \"\"\"\n",
    "        Build CART from root\n",
    "        \"\"\"\n",
    "        self.list_selected_features = self.root.create_with_children(max_cart_depth=self.max_CART_depth,\n",
    "                                                                     min_observations=self.min_observations)\n",
    "\n",
    "    def to_xml(self, xml_file_name):\n",
    "        \"\"\"\n",
    "        write Xml file with tree content\n",
    "        \"\"\"\n",
    "        str_nodes = self.root.to_xml()\n",
    "        with open(xml_file_name, 'w') as file:\n",
    "            file.write(str_nodes)\n",
    "        return str_nodes\n",
    "\n",
    "    def evaluate_input(self, input_torch):\n",
    "        \"\"\"\n",
    "        Evaluate a specific input in the tree and get the predicted class\n",
    "        \"\"\"\n",
    "        return self.root.evaluate_node(input_torch)\n",
    "\n",
    "    def update_confusion_matrix(self, estimated_class, real_class):\n",
    "        self.confusion_matrix[int(estimated_class) - 1][int(real_class) - 1] += 1\n",
    "\n",
    "    def get_f1_scores_per_class(self):\n",
    "        def get_metrics(matrix, the_class):\n",
    "            tp = matrix[the_class, the_class]\n",
    "            fn = torch.sum(matrix[:, the_class]) - tp\n",
    "            fp = torch.sum(matrix[the_class, :]) - tp\n",
    "            tn = torch.sum(matrix) - tp - fp - fn\n",
    "            return tp, tn, fp, fn\n",
    "        f1_scores = {}\n",
    "        for my_class in range(self.confusion_matrix.size(0)):\n",
    "            vp, vn, fp, fn = get_metrics(self.confusion_matrix, my_class)\n",
    "            sensibility_tvp = torch.nan_to_num(vp / (fn + vp))\n",
    "            accuracy_vpp = torch.nan_to_num(vp / (vp + fp))\n",
    "            f1_score = torch.nan_to_num((2 * sensibility_tvp * accuracy_vpp) / (sensibility_tvp + accuracy_vpp))\n",
    "            f1_scores[my_class + 1] = f1_score\n",
    "        return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:25:57.057343200Z",
     "start_time": "2024-04-08T04:25:57.043974100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unitary tests for weighted Gini and entropy, calculated as nodes\n",
    "These tests reach 100% code coverage.\n",
    "\"\"\"\n",
    "\n",
    "def calculate_total_gini(node_left, node_right):\n",
    "    size_left = node_left.data_torch_partition.shape[0]\n",
    "    size_right = node_right.data_torch_partition.shape[0]\n",
    "    size_total = size_left + size_right\n",
    "    gini_left = calculate_gini(node_left.data_torch_partition)\n",
    "    gini_right = calculate_gini(node_right.data_torch_partition)\n",
    "    gini_total = (size_left / size_total) * gini_left + (size_right / size_total) * gini_right\n",
    "    return gini_total\n",
    "\n",
    "def calculate_total_entropy(node_left, node_right):\n",
    "    size_left = node_left.data_torch_partition.shape[0]\n",
    "    size_right = node_right.data_torch_partition.shape[0]\n",
    "    size_total = size_left + size_right\n",
    "    entropy_left = calculate_entropy(node_left.data_torch_partition)\n",
    "    entropy_right = calculate_entropy(node_right.data_torch_partition)\n",
    "    entropy_total = (size_left / size_total) * entropy_left + (size_right / size_total) * entropy_right\n",
    "    return entropy_total\n",
    "\n",
    "data = [\n",
    "        [-64, -56, -61, -66, -71, -82, -81, 1],\n",
    "        [-68, -57, -61, -65, -71, -85, -85, 1],\n",
    "        [-42, -53, -62, -38, -66, -65, -69, 2],\n",
    "        [-44, -55, -61, -41, -66, -72, -68, 2]\n",
    "    ]\n",
    "\n",
    "data_left = [\n",
    "    [-64, -56, -61, -66, -71, -82, -81, 1],\n",
    "    [-68, -57, -61, -65, -71, -85, -85, 2]\n",
    "]\n",
    "\n",
    "data_right = [\n",
    "    [-42, -53, -62, -38, -66, -65, -69, 1],\n",
    "    [-44, -55, -61, -41, -66, -72, -68, 1]\n",
    "]\n",
    "\n",
    "\n",
    "def test_calculate_total_gini():\n",
    "    \"\"\"\n",
    "    Unit test for calculate_total_gini. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_left = NodeCart()\n",
    "    node_right = NodeCart()\n",
    "    node_left.data_torch_partition = torch.tensor(data_left)\n",
    "    node_right.data_torch_partition = torch.tensor(data_right)\n",
    "    gini_total = calculate_total_gini(node_left, node_right)\n",
    "    assert gini_total.item() == 0.25\n",
    "    print(\"PASSED\")\n",
    "\n",
    "def test_calculate_total_entropy():\n",
    "    \"\"\"\n",
    "    Unit test for calculate_total_entropy. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_left = NodeCart()\n",
    "    node_right = NodeCart()\n",
    "    node_left.data_torch_partition = torch.tensor(data_left)\n",
    "    node_right.data_torch_partition = torch.tensor(data_right)\n",
    "    entropy_total = calculate_total_entropy(node_left, node_right)\n",
    "    assert round(entropy_total.item(), 3) == 0.346\n",
    "    print(\"PASSED\")\n",
    "\n",
    "test_calculate_total_gini()\n",
    "test_calculate_total_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:30:48.447785Z",
     "start_time": "2024-04-08T04:30:45.843724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n",
      "PASSED\n",
      "PASSED\n",
      "PASSED\n",
      "PASSED\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unitary tests for select_best_feautre_and_thresh and create_with_children \n",
    "These tests reach 100% code coverage.\n",
    "\"\"\"\n",
    "\n",
    "data_best_feature_and_thresh = torch.Tensor([\n",
    "    [-67, -57, -64, -68, -75, -82, -82, 1],\n",
    "    [-68, -55, -73, -65, -76, -82, -82, 1],\n",
    "    [-68, -55, -67, -70, -76, -82, -81, 1],\n",
    "    [-38, -57, -61, -38, -69, -73, -70, 2],\n",
    "    [-39, -62, -58, -37, -69, -73, -72, 2],\n",
    "    [-35, -58, -61, -38, -67, -71, -71, 2],\n",
    "    [-47, -64, -53, -54, -60, -83, -84, 3],\n",
    "    [-45, -63, -57, -55, -58, -79, -85, 3],\n",
    "    [-45, -63, -57, -53, -57, -81, -84, 3],\n",
    "    [-54, -46, -48, -55, -48, -84, -85, 4],\n",
    "    [-58, -53, -44, -62, -52, -84, -88, 4],\n",
    "    [-61, -52, -48, -61, -45, -90, -88, 4],\n",
    "    [-57, -51, -47, -61, -50, -90, -88, 4],\n",
    "    [-58, -56, -51, -65, -53, -87, -87, 4],\n",
    "    [-62, -53, -52, -59, -48, -87, -92, 4],\n",
    "    [-63, -54, -52, -59, -44, -86, -92, 4],\n",
    "    [-57, -58, -52, -66, -46, -86, -90, 4]\n",
    "])\n",
    "\n",
    "\n",
    "def test_gini_select_best_feature_and_thresh():\n",
    "    \"\"\"\n",
    "    Unit test for select_best_feature_and_thresh. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_tree = NodeCart(gini_entropy_function=\"GINI\")\n",
    "    min_thresh, min_feature, min_gini = node_tree.select_best_feature_and_thresh(data_best_feature_and_thresh)\n",
    "    assert min_thresh == -52.0\n",
    "    assert min_feature == 2\n",
    "    assert round(min_gini, 4) == 0.3529\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_entropy_select_best_feature_and_thresh():\n",
    "    \"\"\"\n",
    "    Unit test for select_best_feature_and_thresh. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_tree = NodeCart(gini_entropy_function=\"ENTROPY\")\n",
    "    min_thresh, min_feature, min_gini = node_tree.select_best_feature_and_thresh(data_best_feature_and_thresh)\n",
    "    assert min_thresh == -52.0\n",
    "    assert min_feature == 2\n",
    "    assert round(min_gini, 4) == 0.5816\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_list_features_select_best_feature_and_thresh():\n",
    "    \"\"\"\n",
    "    Unit test for select_best_feature_and_thresh. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_tree = NodeCart()\n",
    "    list_features_selected = [2]\n",
    "    min_thresh, min_feature, min_gini = node_tree.select_best_feature_and_thresh(data_best_feature_and_thresh, list_features_selected)\n",
    "    assert min_thresh == -53.0\n",
    "    assert min_feature == 4\n",
    "    assert round(min_gini, 4) == 0.3529\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_full_list_features_select_best_feature_and_thresh():\n",
    "    \"\"\"\n",
    "    Unit test for select_best_feature_and_thresh. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_tree = NodeCart()\n",
    "    list_features_selected = [0, 1, 2, 3, 4, 5, 6]\n",
    "    with pytest.raises(ValueError) as exc_info:\n",
    "        node_tree.select_best_feature_and_thresh(data_best_feature_and_thresh, list_features_selected)\n",
    "    assert exc_info.value.args[0] == \"All features have been selected\"\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "data_children = read_dataset(csv_name='wifi_localization.txt')\n",
    "\n",
    "\n",
    "def test_gini_create_with_children():\n",
    "    \"\"\"\n",
    "    Unit test for create_with_children. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_tree = NodeCart(gini_entropy_function=\"GINI\")\n",
    "    node_tree.data_torch_partition = data_children\n",
    "    node_tree.create_with_children()\n",
    "    with open(\"test_gini_create_with_children_tree.xml\", \"r\") as file:\n",
    "        expected = file.read()\n",
    "    result = node_tree.to_xml()\n",
    "    assert main.diff_texts(result, expected) == []\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_entropy_create_with_children():\n",
    "    \"\"\"\n",
    "    Unit test for create_with_children. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    node_tree = NodeCart(gini_entropy_function=\"ENTROPY\")\n",
    "    node_tree.data_torch_partition = data_children\n",
    "    node_tree.create_with_children()\n",
    "    with open(\"test_entropy_create_with_children_tree.xml\", \"r\") as file:\n",
    "        expected = file.read()\n",
    "    result = node_tree.to_xml()\n",
    "    assert main.diff_texts(result, expected) == []\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "test_gini_select_best_feature_and_thresh()\n",
    "test_entropy_select_best_feature_and_thresh()\n",
    "test_list_features_select_best_feature_and_thresh()\n",
    "test_full_list_features_select_best_feature_and_thresh()\n",
    "test_gini_create_with_children()\n",
    "test_entropy_create_with_children()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) (10 puntos)** Implemente la función \"test_CART\" la cual evalúe un CART previamente entrenado para un conjunto de datos $D$ representado en un tensor. Calcule la tasa de aciertos (\"accuracy\"), definida como:\n",
    "\n",
    "$a=\\frac{c}{n}$\n",
    "\n",
    "donde $c$ corresponde a las estimaciones correctas, para tal conjunto de datos y retornela. Comente la implementación, detallando cada función utilizada en la documentación externa.\n",
    "\n",
    "1. Diseñe e implemente al menos 2 pruebas unitarias para esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:32:02.486106500Z",
     "start_time": "2024-04-08T04:32:02.456426Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_cart(dataset_torch, name_xml=\"\", max_cart_depth=3, min_obs_per_leaf=2, gini_entropy_function=\"GINI\"):\n",
    "    \"\"\"\n",
    "    Train CART model\n",
    "    \"\"\"\n",
    "    tree = CART(dataset_torch=dataset_torch, max_cart_depth=max_cart_depth, min_observations=min_obs_per_leaf,\n",
    "                gini_entropy_function=gini_entropy_function)\n",
    "    tree.build_cart()\n",
    "    if name_xml:\n",
    "        tree.to_xml(name_xml)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:32:03.069714900Z",
     "start_time": "2024-04-08T04:32:03.055886200Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_cart(tree, testset_torch):\n",
    "    \"\"\"\n",
    "    Test a previously built CART\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    fails = 0\n",
    "    for observation in testset_torch:\n",
    "        expected = observation[-1]\n",
    "        result, leaf = tree.evaluate_input(observation)\n",
    "        tree.update_confusion_matrix(result, expected)\n",
    "        if expected == result:\n",
    "            leaf.hits += 1\n",
    "            leaf.update_accuracy()\n",
    "            hits += 1\n",
    "        else:\n",
    "            leaf.fails += 1\n",
    "            leaf.update_accuracy()\n",
    "            fails += 1\n",
    "    accuracy = (hits / (hits + fails)) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T04:50:12.790532700Z",
     "start_time": "2024-04-08T04:50:10.020160800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unitary tests for select_best_feautre_and_thresh and create_with_children \n",
    "These tests reach 100% code coverage.\n",
    "\"\"\"\n",
    "\n",
    "def test_cart_gini():\n",
    "    \"\"\"\n",
    "    Unit test for test_cart. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    dataset = read_dataset()\n",
    "    tree = train_cart(dataset, gini_entropy_function=\"GINI\")\n",
    "    accuracy = test_cart(tree, dataset)\n",
    "    assert accuracy == 95.25\n",
    "    print(\"PASSED\")\n",
    "\n",
    "\n",
    "def test_cart_entropy():\n",
    "    \"\"\"\n",
    "    Unit test for test_cart. If no error is raised, then it passed. \n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    dataset = read_dataset()\n",
    "    tree = train_cart(dataset, gini_entropy_function=\"ENTROPY\")\n",
    "    accuracy = test_cart(tree, dataset)\n",
    "    assert accuracy == 94.85\n",
    "    print(\"PASSED\")\n",
    "    \n",
    "test_cart_gini()\n",
    "test_cart_entropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Evaluación del CART (40 puntos)**\n",
    "\n",
    "**1. (20 puntos)** Evalúe el CART implementado con el conjunto de datos completo provisto  https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms usándolo como conjunto de datos de entrenamiento y prueba. Reporte la tasa de aciertos y el F1-score promedio de todas las clases, obtenida e incluya el código de la evaluación. Pruebe con una profundidad máxima de 3 y 4 nodos, siempre con mínimo 2 observaciones por hoja.\n",
    "\n",
    "    a) Realice lo anterior usando la entropía y el coeficiente de Gini. Compare y comente los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tree_full_dataset(max_cart_depth, gini_entropy_function, min_obs_per_leaf=2):\n",
    "    \"\"\"\n",
    "    Function to evaluate the full dataset using the specified max depth and gini or entropy\n",
    "    \"\"\"\n",
    "    dataset = read_dataset(csv_name=\"wifi_localization.txt\")\n",
    "    tree = train_cart(dataset, max_cart_depth=max_cart_depth, gini_entropy_function=gini_entropy_function,\n",
    "                      min_obs_per_leaf=min_obs_per_leaf)\n",
    "    overall_accuracy = test_cart(tree, dataset)\n",
    "    f1_scores = tree.get_f1_scores_per_class()\n",
    "    print(f\"Overall accuracy: {overall_accuracy}\")\n",
    "    print(f\"F1 scores: {f1_scores}\")\n",
    "    return overall_accuracy, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 95.25\n",
      "F1 scores: {1: tensor(0.9940), 2: tensor(0.9198), 3: tensor(0.9070), 4: tensor(0.9889)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.25,\n",
       " {1: tensor(0.9940), 2: tensor(0.9198), 3: tensor(0.9070), 4: tensor(0.9889)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate tree with max depth 3 and Gini\n",
    "\"\"\"\n",
    "evaluate_tree_full_dataset(3, \"GINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 96.55\n",
      "F1 scores: {1: tensor(0.9950), 2: tensor(0.9435), 3: tensor(0.9333), 4: tensor(0.9900)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96.55,\n",
       " {1: tensor(0.9950), 2: tensor(0.9435), 3: tensor(0.9333), 4: tensor(0.9900)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate tree with max depth 4 and Gini\n",
    "\"\"\"\n",
    "evaluate_tree_full_dataset(4, \"GINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 94.85\n",
      "F1 scores: {1: tensor(0.9940), 2: tensor(0.9140), 3: tensor(0.8961), 4: tensor(0.9890)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94.85,\n",
       " {1: tensor(0.9940), 2: tensor(0.9140), 3: tensor(0.8961), 4: tensor(0.9890)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate tree with max depth 3 and Entropy\n",
    "\"\"\"\n",
    "evaluate_tree_full_dataset(3, \"ENTROPY\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 95.89999999999999\n",
      "F1 scores: {1: tensor(0.9940), 2: tensor(0.9248), 3: tensor(0.9247), 4: tensor(0.9920)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.89999999999999,\n",
       " {1: tensor(0.9940), 2: tensor(0.9248), 3: tensor(0.9247), 4: tensor(0.9920)})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate tree with max depth 4 and Entropy\n",
    "\"\"\"\n",
    "evaluate_tree_full_dataset(4, \"ENTROPY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (20 puntos)** Para una profundidad máxima de 3 y 4 nodos: evalúe el CART implementado usando 10 particiones aleatorias del conjunto de datos, con un 70% del conjunto de datos como conjunto de datos de entrenamiento, y el restante 30% como conjunto de datos de prueba. Reporte una tabla con la tasa de aciertos y F1-score promedio de todas las clases, de cada una de las 10 corridas, y el promedio y desviación estándar para las 10 corridas.\n",
    "\n",
    "    a) Realice lo anterior usando la entropía y el coeficiente de Gini. Compare los resultados y comente las posibles ventajas y desventajas de cada función de error. En la comparativa, incluya el tiempo de ejecución en entrenar cada modelo con cada función de error distinta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(csv_name='wifi_localization.txt'):\n",
    "    \"\"\"\n",
    "    Function to split the dataset in a 70 / 30 ratio\n",
    "    \"\"\"\n",
    "    data_frame = pandas.read_table(csv_name, sep=r'\\s+', names=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'ROOM'),\n",
    "                                   dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,\n",
    "                                          'E': np.float64, 'F': np.float64, 'G': np.float64, 'ROOM': np.float64})\n",
    "    shuffled_values = data_frame.sample(frac=1).reset_index(drop=True).values\n",
    "    split_index = int(len(shuffled_values) * 0.7)\n",
    "    train_set = shuffled_values[:split_index]\n",
    "    test_set = shuffled_values[split_index:]\n",
    "    return torch.tensor(train_set), torch.tensor(test_set)\n",
    "\n",
    "def evaluate_train_test_dataset_tree(train_dataset, test_dataset, max_cart_depth, gini_entropy_function, min_obs_per_leaf=2):\n",
    "    \"\"\"\n",
    "    Function to evaluate the tree using the corresponding partitions for train and test\n",
    "    \"\"\"\n",
    "    tree = train_cart(train_dataset, max_cart_depth=max_cart_depth, gini_entropy_function=gini_entropy_function,\n",
    "                      min_obs_per_leaf=min_obs_per_leaf)\n",
    "    overall_accuracy = test_cart(tree, test_dataset)\n",
    "    f1_scores = tree.get_f1_scores_per_class()\n",
    "    print(f\"Overall accuracy: {overall_accuracy}\")\n",
    "    print(f\"F1 scores: {f1_scores}\")\n",
    "    return overall_accuracy, f1_scores\n",
    "\n",
    "partitions = [split_dataset() for x in range(10)]\n",
    "results_gini = {}\n",
    "results_entropy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Overall accuracy: 94.66666666666667\n",
      "F1 scores: {1: tensor(0.9964), 2: tensor(0.9136), 3: tensor(0.8933), 4: tensor(0.9900)}\n",
      "Run 2\n",
      "Overall accuracy: 94.33333333333334\n",
      "F1 scores: {1: tensor(0.9895), 2: tensor(0.8993), 3: tensor(0.9042), 4: tensor(0.9835)}\n",
      "Run 3\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9939), 2: tensor(0.9085), 3: tensor(0.9068), 4: tensor(0.9821)}\n",
      "Run 4\n",
      "Overall accuracy: 93.5\n",
      "F1 scores: {1: tensor(0.9865), 2: tensor(0.8896), 3: tensor(0.8729), 4: tensor(0.9873)}\n",
      "Run 5\n",
      "Overall accuracy: 94.16666666666667\n",
      "F1 scores: {1: tensor(0.9889), 2: tensor(0.9032), 3: tensor(0.8889), 4: tensor(0.9904)}\n",
      "Run 6\n",
      "Overall accuracy: 93.33333333333333\n",
      "F1 scores: {1: tensor(0.9819), 2: tensor(0.8794), 3: tensor(0.8782), 4: tensor(0.9833)}\n",
      "Run 7\n",
      "Overall accuracy: 95.0\n",
      "F1 scores: {1: tensor(0.9827), 2: tensor(0.9241), 3: tensor(0.9039), 4: tensor(0.9847)}\n",
      "Run 8\n",
      "Overall accuracy: 94.5\n",
      "F1 scores: {1: tensor(0.9904), 2: tensor(0.9014), 3: tensor(0.8897), 4: tensor(0.9877)}\n",
      "Run 9\n",
      "Overall accuracy: 95.0\n",
      "F1 scores: {1: tensor(0.9905), 2: tensor(0.9030), 3: tensor(0.9061), 4: tensor(0.9935)}\n",
      "Run 10\n",
      "Overall accuracy: 93.83333333333333\n",
      "F1 scores: {1: tensor(0.9932), 2: tensor(0.8970), 3: tensor(0.8808), 4: tensor(0.9835)}\n",
      "CPU times: total: 38.1 s\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Test tree with random partitions using max_depth 3 and Gini\n",
    "\"\"\"\n",
    "for index, partition in enumerate(partitions):\n",
    "    print(\"Run\",index + 1)\n",
    "    results_gini[f\"{index}, 3\"] = evaluate_train_test_dataset_tree(partition[0], partition[1], max_cart_depth=3, gini_entropy_function=\"GINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Overall accuracy: 95.66666666666667\n",
      "F1 scores: {1: tensor(0.9964), 2: tensor(0.9317), 3: tensor(0.9139), 4: tensor(0.9900)}\n",
      "Run 2\n",
      "Overall accuracy: 96.16666666666667\n",
      "F1 scores: {1: tensor(0.9895), 2: tensor(0.9431), 3: tensor(0.9329), 4: tensor(0.9835)}\n",
      "Run 3\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9939), 2: tensor(0.9150), 3: tensor(0.8997), 4: tensor(0.9821)}\n",
      "Run 4\n",
      "Overall accuracy: 94.16666666666667\n",
      "F1 scores: {1: tensor(0.9831), 2: tensor(0.9034), 3: tensor(0.8933), 4: tensor(0.9841)}\n",
      "Run 5\n",
      "Overall accuracy: 94.16666666666667\n",
      "F1 scores: {1: tensor(0.9889), 2: tensor(0.9032), 3: tensor(0.8889), 4: tensor(0.9904)}\n",
      "Run 6\n",
      "Overall accuracy: 94.16666666666667\n",
      "F1 scores: {1: tensor(0.9879), 2: tensor(0.9037), 3: tensor(0.8896), 4: tensor(0.9767)}\n",
      "Run 7\n",
      "Overall accuracy: 96.0\n",
      "F1 scores: {1: tensor(0.9826), 2: tensor(0.9431), 3: tensor(0.9263), 4: tensor(0.9848)}\n",
      "Run 8\n",
      "Overall accuracy: 95.66666666666667\n",
      "F1 scores: {1: tensor(0.9904), 2: tensor(0.9213), 3: tensor(0.9195), 4: tensor(0.9877)}\n",
      "Run 9\n",
      "Overall accuracy: 94.66666666666667\n",
      "F1 scores: {1: tensor(0.9905), 2: tensor(0.8971), 3: tensor(0.8984), 4: tensor(0.9935)}\n",
      "Run 10\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9932), 2: tensor(0.9147), 3: tensor(0.9032), 4: tensor(0.9835)}\n",
      "CPU times: total: 46.2 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Test tree with random partitions using max_depth 4 and Gini\n",
    "\"\"\"\n",
    "for index, partition in enumerate(partitions):\n",
    "    print(\"Run\",index+1)\n",
    "    results_gini[f\"{index}, 4\"] = evaluate_train_test_dataset_tree(partition[0], partition[1], max_cart_depth=4, gini_entropy_function=\"GINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9964), 2: tensor(0.9114), 3: tensor(0.8990), 4: tensor(0.9934)}\n",
      "Run 2\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9858), 2: tensor(0.9195), 3: tensor(0.9085), 4: tensor(0.9835)}\n",
      "Run 3\n",
      "Overall accuracy: 93.66666666666667\n",
      "F1 scores: {1: tensor(0.9845), 2: tensor(0.9038), 3: tensor(0.8741), 4: tensor(0.9821)}\n",
      "Run 4\n",
      "Overall accuracy: 94.0\n",
      "F1 scores: {1: tensor(0.9865), 2: tensor(0.8966), 3: tensor(0.8867), 4: tensor(0.9873)}\n",
      "Run 5\n",
      "Overall accuracy: 93.83333333333333\n",
      "F1 scores: {1: tensor(0.9889), 2: tensor(0.8994), 3: tensor(0.8792), 4: tensor(0.9904)}\n",
      "Run 6\n",
      "Overall accuracy: 92.66666666666666\n",
      "F1 scores: {1: tensor(0.9760), 2: tensor(0.8800), 3: tensor(0.8562), 4: tensor(0.9833)}\n",
      "Run 7\n",
      "Overall accuracy: 93.33333333333333\n",
      "F1 scores: {1: tensor(0.9861), 2: tensor(0.8952), 3: tensor(0.8593), 4: tensor(0.9847)}\n",
      "Run 8\n",
      "Overall accuracy: 94.5\n",
      "F1 scores: {1: tensor(0.9904), 2: tensor(0.9014), 3: tensor(0.8897), 4: tensor(0.9877)}\n",
      "Run 9\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9905), 2: tensor(0.9004), 3: tensor(0.9020), 4: tensor(0.9935)}\n",
      "Run 10\n",
      "Overall accuracy: 93.83333333333333\n",
      "F1 scores: {1: tensor(0.9932), 2: tensor(0.8970), 3: tensor(0.8808), 4: tensor(0.9835)}\n",
      "CPU times: total: 40.9 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Test tree with random partitions using max_depth 3 and Entropy\n",
    "\"\"\"\n",
    "for index, partition in enumerate(partitions):\n",
    "    print(\"Run\",index+1)\n",
    "    results_entropy[f\"{index}, 3\"] = evaluate_train_test_dataset_tree(partition[0], partition[1], max_cart_depth=3, gini_entropy_function=\"ENTROPY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9964), 2: tensor(0.9114), 3: tensor(0.8990), 4: tensor(0.9934)}\n",
      "Run 2\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9858), 2: tensor(0.9195), 3: tensor(0.9085), 4: tensor(0.9835)}\n",
      "Run 3\n",
      "Overall accuracy: 94.83333333333334\n",
      "F1 scores: {1: tensor(0.9908), 2: tensor(0.9175), 3: tensor(0.9010), 4: tensor(0.9821)}\n",
      "Run 4\n",
      "Overall accuracy: 93.83333333333333\n",
      "F1 scores: {1: tensor(0.9831), 2: tensor(0.8951), 3: tensor(0.8882), 4: tensor(0.9841)}\n",
      "Run 5\n",
      "Overall accuracy: 94.16666666666667\n",
      "F1 scores: {1: tensor(0.9889), 2: tensor(0.9026), 3: tensor(0.8896), 4: tensor(0.9904)}\n",
      "Run 6\n",
      "Overall accuracy: 93.83333333333333\n",
      "F1 scores: {1: tensor(0.9818), 2: tensor(0.8906), 3: tensor(0.8889), 4: tensor(0.9833)}\n",
      "Run 7\n",
      "Overall accuracy: 93.0\n",
      "F1 scores: {1: tensor(0.9827), 2: tensor(0.8851), 3: tensor(0.8611), 4: tensor(0.9847)}\n",
      "Run 8\n",
      "Overall accuracy: 96.5\n",
      "F1 scores: {1: tensor(0.9904), 2: tensor(0.9385), 3: tensor(0.9377), 4: tensor(0.9877)}\n",
      "Run 9\n",
      "Overall accuracy: 95.33333333333334\n",
      "F1 scores: {1: tensor(0.9905), 2: tensor(0.9077), 3: tensor(0.9148), 4: tensor(0.9935)}\n",
      "Run 10\n",
      "Overall accuracy: 95.83333333333334\n",
      "F1 scores: {1: tensor(0.9932), 2: tensor(0.9304), 3: tensor(0.9273), 4: tensor(0.9835)}\n",
      "CPU times: total: 42.7 s\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Test tree with random partitions using max_depth 4 and Entropy\n",
    "\"\"\"\n",
    "for index, partition in enumerate(partitions):\n",
    "    print(\"Run\",index+1)\n",
    "    results_entropy[f\"{index}, 4\"] = evaluate_train_test_dataset_tree(partition[0], partition[1], max_cart_depth=4, gini_entropy_function=\"ENTROPY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (15 puntos extra)** Utilizando Optuna o weights and biases, optimice la profundidad máxima de los nodos. Muestre los gráficos de la optimización realizada con la herramienta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Function to set the trials for Optuna\n",
    "    \"\"\"\n",
    "    dataset = read_dataset(csv_name=\"wifi_localization.txt\")\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 8)\n",
    "    tree = train_cart(dataset, max_cart_depth=max_depth, gini_entropy_function=\"ENTROPY\")\n",
    "    accuracy = test_cart(tree, dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-07 20:17:00,442] A new study created in memory with name: no-name-de6fe6cb-aeb8-42ef-9e9f-7482d21f35f8\n",
      "[I 2024-04-07 20:17:00,680] Trial 0 finished with value: 93.8 and parameters: {'max_depth': 2}. Best is trial 0 with value: 93.8.\n",
      "[I 2024-04-07 20:17:01,124] Trial 1 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:01,587] Trial 2 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:01,818] Trial 3 finished with value: 93.8 and parameters: {'max_depth': 2}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:02,278] Trial 4 finished with value: 96.89999999999999 and parameters: {'max_depth': 5}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:02,520] Trial 5 finished with value: 93.8 and parameters: {'max_depth': 2}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:03,017] Trial 6 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:03,418] Trial 7 finished with value: 95.89999999999999 and parameters: {'max_depth': 4}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:03,581] Trial 8 finished with value: 50.0 and parameters: {'max_depth': 1}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:04,030] Trial 9 finished with value: 96.89999999999999 and parameters: {'max_depth': 5}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:04,495] Trial 10 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:04,965] Trial 11 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:05,427] Trial 12 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:05,880] Trial 13 finished with value: 97.15 and parameters: {'max_depth': 6}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:06,361] Trial 14 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:06,838] Trial 15 finished with value: 97.15 and parameters: {'max_depth': 6}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:07,327] Trial 16 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:07,734] Trial 17 finished with value: 95.89999999999999 and parameters: {'max_depth': 4}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:08,220] Trial 18 finished with value: 97.15 and parameters: {'max_depth': 6}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:08,688] Trial 19 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:09,150] Trial 20 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:09,611] Trial 21 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:10,059] Trial 22 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:10,511] Trial 23 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:11,001] Trial 24 finished with value: 97.15 and parameters: {'max_depth': 6}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:11,463] Trial 25 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:11,940] Trial 26 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:12,373] Trial 27 finished with value: 96.89999999999999 and parameters: {'max_depth': 5}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:12,805] Trial 28 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:13,133] Trial 29 finished with value: 94.85 and parameters: {'max_depth': 3}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:13,608] Trial 30 finished with value: 97.15 and parameters: {'max_depth': 6}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:14,109] Trial 31 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:14,578] Trial 32 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:15,044] Trial 33 finished with value: 97.15 and parameters: {'max_depth': 8}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:15,503] Trial 34 finished with value: 97.15 and parameters: {'max_depth': 7}. Best is trial 1 with value: 97.15.\n",
      "[I 2024-04-07 20:17:15,968] Trial 35 finished with value: 97.15 and parameters: {'max_depth': 6}. Best is trial 1 with value: 97.15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: 6\n",
      "Best accuracy: 97.15%\n",
      "CPU times: total: 3min 32s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Defining the Optuna study and direction\n",
    "\"\"\"\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=36)\n",
    "\n",
    "lowest_depth = None\n",
    "for trial in study.best_trials:\n",
    "    depth = trial.params['max_depth']\n",
    "    lowest_depth = depth if lowest_depth is None or depth < lowest_depth else lowest_depth\n",
    "\n",
    "print(f\"Best parameter: {lowest_depth}\")\n",
    "print(f\"Best accuracy: {study.best_value}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          93.8,
          97.15,
          97.15,
          93.8,
          96.89999999999999,
          93.8,
          97.15,
          95.89999999999999,
          50,
          96.89999999999999,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          95.89999999999999,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          96.89999999999999,
          97.15,
          94.85,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35
         ],
         "y": [
          93.8,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15,
          97.15
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Prueba"
         }
        },
        "yaxis": {
         "title": {
          "text": "Precisión"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot the Optuna optimization history with the built-in functions\n",
    "\"\"\"\n",
    "\n",
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.update_layout(xaxis_title='Prueba', yaxis_title='Precisión')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 97.3\n",
      "F1 scores: {1: tensor(0.9950), 2: tensor(0.9579), 3: tensor(0.9492), 4: tensor(0.9900)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97.3,\n",
       " {1: tensor(0.9950), 2: tensor(0.9579), 3: tensor(0.9492), 4: tensor(0.9900)})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a new full tree with the recommended parameter from Optuna\n",
    "\"\"\"\n",
    "evaluate_tree_full_dataset(6, \"GINI\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5020b9ee0a8929ac5eb1b3fdb8306c158218ab19e75e568837c0f095b545b9d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
